{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1b4d8dd-104e-475f-bad6-1c5604863cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ca514a1-ce78-4a19-9746-445fa8ff10c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchmetrics.functional.classification.jaccard import jaccard_index\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from colorama import Fore\n",
    "\n",
    "from WeatherNet.weathernet import WeatherNet\n",
    "\n",
    "from dataloader.dataset import WADS\n",
    "from dataloader.dataloader import WADSLoader\n",
    "\n",
    "from SalsaNext.KNN import KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a567a5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d166503-eedd-4f3c-ba6f-72441bf4769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'projection_H': 64,\n",
    "          'projection_W': 2048,\n",
    "          'sensor_fov_up': 3,\n",
    "          'sensor_fov_down': -25,\n",
    "          'sensor_img_means': [-12.12, -10.88, -0.23, -1.04, -0.21],\n",
    "          'sensor_img_stds': [-12.32, -11.47, -6.91, -0.86, -0.16],\n",
    "          'max_points': 250000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1334d755-b4d0-4639-8ead-a6e55dcc46b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 0\n",
      "Number of validation samples: 0\n",
      "Number of test samples: 0\n"
     ]
    }
   ],
   "source": [
    "train_ds = WADS(\"/tmp/wads_dataset/clean_dataset/Training/\", config)\n",
    "valid_ds = WADS(\"/tmp/wads_dataset/clean_dataset/Validation/\", config)\n",
    "test_ds = WADS(\"/tmp/wads_dataset/clean_dataset/Test/\", config)\n",
    "\n",
    "print(\"Number of training samples:\", len(train_ds))\n",
    "print(\"Number of validation samples:\",len(valid_ds))\n",
    "print(\"Number of test samples:\",len(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e1e9246-4b01-4c68-aeb3-ea61ba92627e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pudhin\\Downloads\\Lidar-WeatherNet-main\\Lidar-WeatherNet-main\\WeatherNet.ipynb Cell 6\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pudhin/Downloads/Lidar-WeatherNet-main/Lidar-WeatherNet-main/WeatherNet.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mprint\u001b[39m(train_ds\u001b[39m.\u001b[39mlabels[idx])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pudhin/Downloads/Lidar-WeatherNet-main/Lidar-WeatherNet-main/WeatherNet.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m idx \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/pudhin/Downloads/Lidar-WeatherNet-main/Lidar-WeatherNet-main/WeatherNet.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(train_ds\u001b[39m.\u001b[39;49mscans[idx])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pudhin/Downloads/Lidar-WeatherNet-main/Lidar-WeatherNet-main/WeatherNet.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(train_ds\u001b[39m.\u001b[39mlabels[idx])\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "idx = 100\n",
    "if 0 <= idx < len(train_ds.scans):\n",
    "    print(train_ds.scans[idx])\n",
    "    print(train_ds.labels[idx])\n",
    "\n",
    "idx = 100\n",
    "print(train_ds.scans[idx])\n",
    "print(train_ds.labels[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab84f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = train_ds[idx]\n",
    "print(sample.proj_xyz.shape)\n",
    "print(sample.proj_range.shape)\n",
    "print(sample.proj_remission.shape)\n",
    "print(sample.proj_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2caf1d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Projection result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23123e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pudhin\\Downloads\\Lidar-WeatherNet-main\\Lidar-WeatherNet-main\\WeatherNet.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/pudhin/Downloads/Lidar-WeatherNet-main/Lidar-WeatherNet-main/WeatherNet.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m fig, axes \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(nrows\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, figsize\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m, \u001b[39m3\u001b[39m), dpi\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pudhin/Downloads/Lidar-WeatherNet-main/Lidar-WeatherNet-main/WeatherNet.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m3\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pudhin/Downloads/Lidar-WeatherNet-main/Lidar-WeatherNet-main/WeatherNet.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     axes[i]\u001b[39m.\u001b[39mimshow(sample\u001b[39m.\u001b[39mproj_xyz[i, :, :])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=3, figsize=(10, 3), dpi=1000)\n",
    "for i in range(3):\n",
    "    axes[i].imshow(sample.proj_xyz[i, :, :])\n",
    "fig.suptitle(\"proj_xyz\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 1), dpi=1000)\n",
    "ax.imshow(torch.squeeze(sample.proj_range))\n",
    "fig.suptitle(\"proj_range\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 1), dpi=1000)\n",
    "ax.imshow(torch.squeeze(sample.proj_remission))\n",
    "fig.suptitle(\"proj_remission\");\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 1), dpi=1000)\n",
    "ax.imshow(torch.squeeze(sample.proj_labels))\n",
    "fig.suptitle(\"proj_labels\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdfccce-f135-471c-acba-16f9cc98ffc8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a98e1b-91a3-4b2a-afdd-e659af4ce929",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hparams = {'train_ds': train_ds,\n",
    "           'valid_ds': valid_ds,\n",
    "           'test_ds': test_ds,\n",
    "           'train_batch_size': 2,\n",
    "           'valid_batch_size': 1,\n",
    "           'test_batch_size': 1,\n",
    "           'train_shuffle': True,\n",
    "           'valid_shuffle': False,\n",
    "           'test_shuffle': False,\n",
    "           'num_workers': 20}\n",
    "\n",
    "train_dataloader = WADSLoader(**hparams).train_dataloader()\n",
    "valid_dataloader = WADSLoader(**hparams).validation_dataloader()\n",
    "test_dataloader = WADSLoader(**hparams).test_dataloader()\n",
    "\n",
    "batch = next(iter(train_dataloader))\n",
    "\n",
    "print(batch.proj_xyz.shape)\n",
    "print(batch.proj_range.shape)\n",
    "print(batch.proj_remission.shape)\n",
    "print(batch.proj_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9bd7da-5f10-4153-9212-952e072fa21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "# num_classes=1 using sigmoid\n",
    "model =  WeatherNet(num_classes=1)\n",
    "# Multi-GPU Training\n",
    "model= nn.DataParallel(model)\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb311ebb-cefc-495d-a4a7-002291af033d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=0.3)\n",
    "criterion = nn.BCELoss()\n",
    "writer = SummaryWriter()\n",
    "scheduler = ExponentialLR(optimizer, gamma=0.999)\n",
    "sigmoid = nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e686808b-68a4-4bf2-a940-9f0d85459ffa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "train_ious = []\n",
    "valid_ious = []\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "best_loss = 100\n",
    "best_iou = 0\n",
    "saved = False\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(Fore.YELLOW + f\"Epoch: {(epoch+1):02}/{epochs}\")\n",
    "    for step, (proj_in, proj_mask, proj_labels, unproj_labels, path_seq, path_name, p_x, p_y, proj_range, unproj_range, proj_xyz, unproj_xyz, proj_remission, unproj_remissions, npoints) in enumerate(train_dataloader):\n",
    "        # Use weighted BCE for class imbalance: weight = sqrt(frequency)\n",
    "        label_0_freq = (proj_labels==0).sum().item()\n",
    "        label_1_freq = (proj_labels==1).sum().item()\n",
    "        weight = torch.where(proj_labels==0, 1/label_0_freq**0.5, 1/label_1_freq**0.5).to(device)\n",
    "        criterion.weight = weight\n",
    "        \n",
    "        output = model(proj_range.to(device), proj_remission.to(device))\n",
    "        output = sigmoid(output)\n",
    "        pred = torch.where(output>=0.5, 1, 0)\n",
    "        loss = criterion(output.float().to(device), proj_labels.float().to(device))\n",
    "        iou = jaccard_index(proj_labels.cpu(), pred.cpu(), num_classes=2)\n",
    "        \n",
    "        optimizer.zero_grad()           \n",
    "        loss.backward()                 \n",
    "        optimizer.step()\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "        train_ious.append(iou.item())\n",
    "\n",
    "        if ((step % (len(train_dataloader)//5)) == 0) or (step == len(train_dataloader)):\n",
    "            train_loss = sum(train_losses)/len(train_losses)\n",
    "            train_iou = sum(train_ious)/len(train_ious)\n",
    "            writer.add_scalar('train_loss', train_loss, epoch * len(train_dataloader) + step)\n",
    "            writer.add_scalar('train_iou', train_iou, epoch * len(train_dataloader) + step)\n",
    "            train_losses.clear()\n",
    "            train_ious.clear()\n",
    "            \n",
    "            model.eval() \n",
    "            with torch.no_grad():\n",
    "                for proj_in, proj_mask, proj_labels, unproj_labels, path_seq, path_name, p_x, p_y, proj_range, unproj_range, proj_xyz, unproj_xyz, proj_remission, unproj_remissions, npoints in valid_dataloader:\n",
    "                    criterion.weight = None\n",
    "                    output = model(proj_range.to(device), proj_remission.to(device))\n",
    "                    output = sigmoid(output)\n",
    "                    pred = torch.where(output>=0.5, 1, 0)\n",
    "                    loss = criterion(output.float().to(device), proj_labels.float().to(device))\n",
    "                    iou = jaccard_index(proj_labels.cpu(), pred.cpu(), num_classes=2)\n",
    "                    valid_losses.append(loss.item())\n",
    "                    valid_ious.append(iou.item())\n",
    "                \n",
    "            valid_loss = sum(valid_losses)/len(valid_losses)\n",
    "            valid_iou = sum(valid_ious)/len(valid_ious)\n",
    "            writer.add_scalar('valid_loss', valid_loss, epoch * len(train_dataloader) + step)\n",
    "            writer.add_scalar('valid_iou', valid_iou, epoch * len(train_dataloader) + step)\n",
    "            valid_losses.clear()\n",
    "            valid_ious.clear()\n",
    "            \n",
    "            if best_loss > valid_loss:\n",
    "                best_loss = valid_loss\n",
    "                best_model_loss = deepcopy(model.state_dict())\n",
    "                torch.save(best_model_loss, \"Best Model/best_model_2048_loss.pt\")\n",
    "                saved = True\n",
    "                \n",
    "            if best_iou < valid_iou:\n",
    "                best_iou = valid_iou\n",
    "                best_model_iou = deepcopy(model.state_dict())\n",
    "                torch.save(best_model_iou, \"Best Model/best_model_2048_iou.pt\")\n",
    "                saved = True\n",
    "                \n",
    "            if saved:\n",
    "                print(Fore.GREEN + f\"Training Loss(IoU): {train_loss:.6f}({train_iou*100:.2f}), Validation Loss(IoU): {valid_loss:.6f}({valid_iou*100:.2f})\")\n",
    "                saved = False\n",
    "            else:\n",
    "                print(Fore.RED + f\"Training Loss(IoU): {train_loss:.6f}({train_iou*100:.2f}), Validation Loss(IoU): {valid_loss:.6f}({valid_iou*100:.2f})\")\n",
    "\n",
    "            model.train()\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    print(Fore.YELLOW + \"=\" * 74)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1026427-f39c-4174-8a44-5e0e682624ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model Save and Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45713915-a13f-4a74-993a-3aa2a4d5445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model_loss, \"Best Model/best_model_2048_loss.pt\")\n",
    "torch.save(best_model_iou, \"Best Model/best_model_2048_iou.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ecc166-5477-4dba-a7a1-9f1d978ba1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"Best Model/best_model_2048_iou.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d7b8c4-64f8-4fdc-8753-8fdbe369c8e9",
   "metadata": {},
   "source": [
    "# Quantitative Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942f36c2-82ac-4255-8e46-44c9068d1437",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "def evaluate(model, dataloader):\n",
    "    losses = []\n",
    "    ious = []\n",
    "    preds = []\n",
    "    labels = []\n",
    "    preds_flatten = []\n",
    "    labels_flatten = []\n",
    "    \n",
    "    model.eval() \n",
    "    with torch.no_grad():\n",
    "        for sample in dataloader:\n",
    "            criterion.weight = None\n",
    "            output = model(sample.proj_range.to(device), sample.proj_remission.to(device))\n",
    "            output = sigmoid(output)\n",
    "            pred = torch.where(output>=0.5, 1, 0)\n",
    "            loss = criterion(output.float().to(device), sample.proj_labels.float().to(device))\n",
    "            iou = jaccard_index(sample.proj_labels.cpu(), pred.cpu(), num_classes=2)\n",
    "            \n",
    "            preds.append(pred.cpu())\n",
    "            labels.append(sample.proj_labels.cpu())\n",
    "            \n",
    "            losses.append(loss.item())\n",
    "            ious.append(iou.item())\n",
    "\n",
    "    loss = sum(losses)/len(losses)\n",
    "    iou = sum(ious)/len(ious)\n",
    "    \n",
    "    \n",
    "    # Concatenate all predictions and labels\n",
    "    preds = torch.concat(preds, dim=0)\n",
    "    labels = torch.concat(labels, dim=0)\n",
    "    \n",
    "    # Flattening predictions and labels to feed to classification_report\n",
    "    for i in range(labels.shape[0]):\n",
    "        labels_flatten.append(labels[i].squeeze().flatten())\n",
    "        preds_flatten.append(preds[i].squeeze().flatten())\n",
    "    \n",
    "    # Concatenate all flattened predictions and labels\n",
    "    preds_flatten = torch.concat(preds_flatten, dim=0)\n",
    "    labels_flatten = torch.concat(labels_flatten, dim=0)\n",
    "    \n",
    "    # Print classification report and plot confusion matrix\n",
    "    print(classification_report(labels_flatten, preds_flatten, labels=[0, 1]))\n",
    "    cm = confusion_matrix(labels_flatten, preds_flatten, normalize='true')\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot();\n",
    "    \n",
    "    return iou, loss, labels, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae85fbc-d870-495e-a182-b7d266571ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_iou, loss, labels, preds = evaluate(model, valid_dataloader)\n",
    "print(f\"Validation IoU: {valid_iou*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c89ad0e-47c3-4f4d-989b-38f761c4c2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iou, loss, labels, preds = evaluate(model, test_dataloader)\n",
    "print(f\"Test IoU: {test_iou*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776c4a46-7c83-421f-bdea-73d4bbba9d02",
   "metadata": {},
   "source": [
    "# Qualitative Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d7c253-8e0e-43bf-9ee2-de84b408cdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a random rample for evaluation\n",
    "idx = randint(0, labels.shape[0])\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(10,3), nrows=2, dpi=1000)\n",
    "axes[0].imshow(preds[idx].cpu().squeeze())\n",
    "axes[0].set_title(f\"Prediction of sample {idx}\");\n",
    "\n",
    "axes[1].imshow(labels[idx].cpu().squeeze())\n",
    "axes[1].set_title(f\"Label of sample {idx}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da94d06a-f938-4d64-aa50-2e4b01de372a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Unprojection using KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5325b3dc-ddb1-4b79-bbd0-c2166560d131",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_params = {'post': True,\n",
    "              'knn': 5,\n",
    "              'search': 11,\n",
    "              'cutoff': 20,\n",
    "              'sigma': 1.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9d0b9d-1b12-4d88-8e11-1c698113d869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code inspired by \"https://github.com/Halmstad-University/SalsaNext/blob/master/train/tasks/semantic/modules/user.py\"\n",
    "def knn(dataloader, model, knn_params):\n",
    "        proj_preds_list = []\n",
    "        proj_labels_list = []\n",
    "        unproj_preds_list = []\n",
    "        unproj_labels_list = []\n",
    "        \n",
    "        postproc = KNN(knn_params, 2)\n",
    "        \n",
    "        model.eval()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i, (proj_in, proj_mask, proj_labels, unproj_labels, path_seq, path_name, p_x, p_y, proj_range, unproj_range, proj_xyz, unproj_xyz, proj_remission, unproj_remissions, npoints) in enumerate(dataloader):\n",
    "                p_x = p_x[0, :npoints]\n",
    "                p_y = p_y[0, :npoints]\n",
    "                proj_range = proj_range[0, :npoints].unsqueeze(1)\n",
    "                unproj_range = unproj_range[0, :npoints]\n",
    "                path_seq = path_seq[0]\n",
    "                path_name = path_name[0]\n",
    "\n",
    "                proj_in = proj_in.cuda()\n",
    "                p_x = p_x.cuda()\n",
    "                p_y = p_y.cuda()\n",
    "                proj_range = proj_range.cuda()\n",
    "                unproj_range = unproj_range.cuda()\n",
    "\n",
    "                proj_output = sigmoid(model(proj_range, proj_remission))\n",
    "                proj_argmax = torch.where(proj_output>0.5, 1, 0)\n",
    "\n",
    "                torch.cuda.synchronize()\n",
    "\n",
    "\n",
    "                unproj_argmax = postproc(proj_range.squeeze(),\n",
    "                                         unproj_range.squeeze(),\n",
    "                                         proj_argmax.squeeze(),\n",
    "                                         p_x.squeeze(),\n",
    "                                         p_y.squeeze())\n",
    "\n",
    "                proj_labels_list.append(proj_labels.squeeze())\n",
    "                proj_preds_list.append(proj_argmax.squeeze())\n",
    "\n",
    "                unproj_labels_list.append(unproj_labels.squeeze()[: len(unproj_argmax)])\n",
    "                unproj_preds_list.append(unproj_argmax)\n",
    "                \n",
    "        return proj_labels_list, proj_preds_list, unproj_labels_list, unproj_preds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b7eb53-86a0-4625-80c0-5916720a268f",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_labels, proj_preds, unproj_labels, unproj_preds = knn(valid_dataloader, model, knn_params)\n",
    "\n",
    "accs = []\n",
    "for i in range(len(unproj_labels)):\n",
    "    accs.append((((unproj_labels[i].cpu()==unproj_preds[i].cpu()).sum())/len(unproj_labels[i])).item())\n",
    "print(f'Average validation accuracy: {(sum(accs)/len(accs))*100:.2f}%')\n",
    "\n",
    "ious = []\n",
    "for i in range(len(unproj_labels)):\n",
    "    ious.append(jaccard_index(unproj_labels[i].cpu(), unproj_preds[i].cpu(), 2).item())\n",
    "print(f'Average validation IoU: {(sum(ious)/len(ious))*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996cfdde-2a58-4b08-a33d-c2d65ca5c33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_labels, proj_preds, unproj_labels, unproj_preds = knn(test_dataloader, model, knn_params)\n",
    "\n",
    "accs = []\n",
    "for i in range(len(unproj_labels)):\n",
    "    accs.append((((unproj_labels[i].cpu()==unproj_preds[i].cpu()).sum())/len(unproj_labels[i])).item())\n",
    "print(f'Average test accuracy: {(sum(accs)/len(accs))*100:.2f}%')\n",
    "\n",
    "ious = []\n",
    "for i in range(len(unproj_labels)):\n",
    "    ious.append(jaccard_index(unproj_labels[i].cpu(), unproj_preds[i].cpu(), 2).item())\n",
    "print(f'Average test IoU: {(sum(ious)/len(ious))*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b557ad3a-a8e7-4b08-92dc-1b449707d0e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
